{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-27T19:13:08.152273Z",
     "iopub.status.busy": "2024-11-27T19:13:08.151549Z",
     "iopub.status.idle": "2024-11-27T19:13:09.583325Z",
     "shell.execute_reply": "2024-11-27T19:13:09.582293Z",
     "shell.execute_reply.started": "2024-11-27T19:13:08.152208Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with open('/kaggle/input/Persian-WikiText-1.txt','r') as f : \n",
    "    data = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T19:13:33.049997Z",
     "iopub.status.busy": "2024-11-27T19:13:33.049691Z",
     "iopub.status.idle": "2024-11-27T19:16:15.939073Z",
     "shell.execute_reply": "2024-11-27T19:16:15.938053Z",
     "shell.execute_reply.started": "2024-11-27T19:13:33.049963Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2002065cef55409a9608214d2cb9fff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/176 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f13b7f45af97476b972fab2605f464d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.33M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4c3d7f44375424386989cd903b8a7e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/3.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing text: 100%|██████████| 446023/446023 [01:57<00:00, 3799.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pretrained BPE tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing with BPE: 100%|██████████| 208995/208995 [00:31<00:00, 6584.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BPE Tokenization completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from hazm import Normalizer, word_tokenize, Lemmatizer, stopwords_list\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import re\n",
    "\n",
    "# Initialize Hazm tools\n",
    "normalizer = Normalizer()\n",
    "lemmatizer = Lemmatizer()\n",
    "stop_words = set(stopwords_list())\n",
    "\n",
    "# Define regex patterns\n",
    "english_word_pattern = re.compile(r'[A-Za-z]')\n",
    "punctuation_pattern = re.compile(r'[^\\w\\s\\u0600-\\u06FF]')\n",
    "\n",
    "# Load the tokenizer globally to avoid re-loading in parallel processes\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mshojaei77/PersianBPETokenizer\")\n",
    "vocab = set(tokenizer.get_vocab().keys())  # Cache tokenizer vocabulary for faster lookups\n",
    "\n",
    "\n",
    "def preprocess_text_single(data):\n",
    "    \"\"\"\n",
    "    Process a single string of Persian text for normalization, tokenization, and removing unnecessary tokens.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Normalize the text\n",
    "        data = normalizer.normalize(data)\n",
    "\n",
    "        # Tokenize the text\n",
    "        tokens = word_tokenize(data)\n",
    "\n",
    "        # Remove English words and stop words\n",
    "        tokens = [token for token in tokens if not english_word_pattern.search(token)]\n",
    "\n",
    "        # Lemmatize tokens\n",
    "        tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "        # Remove punctuation\n",
    "        tokens = [token for token in tokens if not punctuation_pattern.search(token)]\n",
    "\n",
    "        # Filter tokens using tokenizer vocabulary\n",
    "        tokens = [token for token in tokens if token in vocab]\n",
    "\n",
    "        return \" \".join(tokens) if tokens else None\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def preprocess_text_parallel(data_batch, num_workers=None):\n",
    "    \"\"\"\n",
    "    Process a batch of Persian text using multiprocessing for faster preprocessing.\n",
    "    \"\"\"\n",
    "    num_workers = num_workers or max(1, cpu_count() - 1)  # Use all but one CPU core by default\n",
    "    with Pool(processes=num_workers) as pool:\n",
    "        processed_results = list(tqdm(pool.imap(preprocess_text_single, data_batch), \n",
    "                                      total=len(data_batch), desc=\"Preprocessing text\"))\n",
    "    # Remove None results (failed cases)\n",
    "    return [result for result in processed_results if result is not None]\n",
    "\n",
    "\n",
    "def tokenize_with_bpe(processed_corpus):\n",
    "    \"\"\"\n",
    "    Tokenize text using the pretrained Persian BPE tokenizer.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Encode the text with fallback for OOV tokens\n",
    "        return [\n",
    "            tokenizer.encode(sentence, add_special_tokens=False)\n",
    "            for sentence in tqdm(processed_corpus, desc=\"Tokenizing with BPE\")\n",
    "        ]\n",
    "    except Exception as e:\n",
    "        print(f\"Error during tokenization: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# Preprocess the corpus in parallel\n",
    "print(\"Preprocessing text...\")\n",
    "processed_corpus = preprocess_text_parallel(data)\n",
    "\n",
    "# Tokenize the preprocessed corpus\n",
    "print(\"Using pretrained BPE tokenizer...\")\n",
    "tokenized_corpus = tokenize_with_bpe(processed_corpus)\n",
    "\n",
    "if tokenized_corpus is not None:\n",
    "    print(\"BPE Tokenization completed.\")\n",
    "else:\n",
    "    print(\"BPE Tokenization failed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Explanation about preprocessing steps</h1>\n",
    "In this preprocessing step, I decided not to remove stop words because the generated sentences seem unreadable. It is suggested to remove stop words because they are frequent in data, and the model will overfit and constantly predict them as the next token; however, in my setting, the model learns to predict them less. My preprocessing step includes removing English words, punctuation, and converting to BPE.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>why we need lemmatizer</h1>\n",
    "\n",
    "We use a lemmatizer to bring each word to its base form, which helps achieve consistency by handling different versions of a word as the same and reducing dimensionality.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> How BPE works,Benefits and drawbacks</h1>\n",
    "\n",
    "**How it Works:**\n",
    "- **Step 1**: Start with a vocabulary of single characters (e.g., letters or bytes).\n",
    "- **Step 2**: Identify the most frequent pair of characters in a dataset.\n",
    "- **Step 3**: Merge this pair into a new \"token\" (e.g., combining \"th\" into a single token if it's frequent).\n",
    "- **Step 4**: Repeat the merging process until the desired vocabulary size is reached or all frequent pairs are merged.\n",
    "\n",
    "**Pros:**\n",
    "1. **Efficient Vocabulary Size**: Creates a balance between small subword units (e.g., \"t\", \"h\") and larger words or phrases.\n",
    "2. **Better Handling of Rare Words**: Breaks rare or unknown words into smaller, meaningful subwords, reducing out-of-vocabulary issues.\n",
    "3. **Language Agnostic**: Can be applied to almost any language without major modification.\n",
    "4. **Compact Representation**: Reduces memory usage compared to character-based models.\n",
    "\n",
    "**Cons:**\n",
    "1. **Static Vocabulary**: Once trained, the vocabulary cannot adapt dynamically to new data or tokens.\n",
    "2. **Suboptimal for Morphologically Rich Languages**: Struggles with languages that have complex morphology.\n",
    "3. **Merging Order Dependency**: Results depend heavily on the initial frequency distribution of tokens in the training data.\n",
    "4. **Token Splitting Variability**: Different merges can cause inconsistencies in tokenization across datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class NGramDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom PyTorch Dataset for n-gram training on tokenized data.\n",
    "    \"\"\"\n",
    "    def __init__(self, processed_data, n=3, device=\"cpu\"):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            processed_data (list): List of dictionaries containing 'input_ids' for each text.\n",
    "            n (int): The size of the n-grams.\n",
    "            device (str): The device to move tensors to (\"cpu\" or \"cuda\").\n",
    "        \"\"\"\n",
    "        self.data = processed_data\n",
    "        self.n = n\n",
    "        self.device = device\n",
    "        self.ngrams = self.generate_ngrams()\n",
    "    \n",
    "    def generate_ngrams(self):\n",
    "        \"\"\"\n",
    "        Generate n-grams from the tokenized data.\n",
    "        Returns:\n",
    "            List of tuples (context, target) where:\n",
    "                - context: A tensor of n-1 tokens (input).\n",
    "                - target: A tensor of 1 token (output).\n",
    "        \"\"\"\n",
    "        ngrams = []\n",
    "        for tokens in self.data:\n",
    "            if len(tokens) < self.n:\n",
    "                continue  # Skip short sequences\n",
    "            for i in range(len(tokens) - self.n + 1):\n",
    "                context = tokens[i:i + self.n - 1]\n",
    "                target = tokens[i + self.n - 1]\n",
    "                # Move tensors to the specified device\n",
    "                ngrams.append(\n",
    "                    (torch.tensor(context, dtype=torch.long, device=self.device),\n",
    "                     torch.tensor(target, dtype=torch.long, device=self.device))\n",
    "                )\n",
    "        return ngrams\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ngrams)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.ngrams[idx]\n",
    "\n",
    "# Set n-gram size\n",
    "n = 10\n",
    "\n",
    "# Initialize the dataset and ensure tensors are created on the correct device\n",
    "dataset = NGramDataset(tokenized_corpus, n=n, device='cpu')\n",
    "\n",
    "# Create DataLoader\n",
    "batch_size = 128\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class NGramRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, n):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            vocab_size (int): Size of the vocabulary.\n",
    "            embedding_dim (int): Dimensionality of token embeddings.\n",
    "            hidden_dim (int): Dimensionality of the RNN's hidden state.\n",
    "            n (int): Size of n-grams (context length = n-1).\n",
    "        \"\"\"\n",
    "        super(NGramRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)  # Embedding layer\n",
    "        self.rnn = nn.GRU(embedding_dim, hidden_dim, batch_first=True,num_layers=2)  # LSTM layer\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)  # Fully connected output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the model.\n",
    "        Args:\n",
    "            x (Tensor): Input tensor of shape [batch_size, seq_len].\n",
    "        Returns:\n",
    "            Tensor: Output logits of shape [batch_size, vocab_size].\n",
    "        \"\"\"\n",
    "        # Step 1: Embed the input tokens\n",
    "        embeds = self.embedding(x)  # Shape: [batch_size, seq_len, embedding_dim]\n",
    "\n",
    "        # Step 2: Pass embeddings through the RNN\n",
    "        out, _ = self.rnn(embeds)  # Shape: [batch_size, seq_len, hidden_dim]\n",
    "\n",
    "        # Step 3: Use the last hidden state to predict the next token\n",
    "        out = self.fc(out[:, -1, :])  # Shape: [batch_size, vocab_size]\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def generate_sentence(model, tokenizer, seed_text, max_len=50):\n",
    "    \"\"\"\n",
    "    Generate a sentence using the trained model with sampling.\n",
    "    Args:\n",
    "        model (torch.nn.Module): The trained n-gram model.\n",
    "        tokenizer: Tokenizer for encoding/decoding.\n",
    "        seed_text (str): Starting sequence for sentence generation.\n",
    "        max_len (int): Maximum length of the generated sequence.\n",
    "    Returns:\n",
    "        str: Generated sentence.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    generated = seed_text\n",
    "    input_ids = torch.tensor(tokenizer.encode(seed_text)).unsqueeze(0).to('cuda')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_len):\n",
    "            # Get the model's prediction\n",
    "            output = model(input_ids)  # Shape: [1, vocab_size]\n",
    "            probabilities = torch.softmax(output, dim=-1).squeeze(0)  # Convert logits to probabilities\n",
    "            \n",
    "            # Sample a token from the probability distribution\n",
    "            next_token_id = torch.multinomial(probabilities, num_samples=1).item()\n",
    "            \n",
    "            # Append the predicted token to the sequence\n",
    "            generated += tokenizer.decode([next_token_id])+' '\n",
    "            # Update input_ids for the next prediction\n",
    "            input_ids = torch.cat((input_ids[:, 1:], torch.tensor([[next_token_id]], device='cuda')), dim=1)\n",
    "\n",
    "    return generated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Hyperparameters\n",
    "epochs = 15\n",
    "learning_rate = 0.1\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Initialize model\n",
    "model = NGramRNN(vocab_size=30000, embedding_dim=512, hidden_dim=64, n=10).to(device)\n",
    "\n",
    "#model.load_state_dict(torch.load('/kaggle/working/model_epoch_5.pth', weights_only=True))\n",
    "\n",
    "# Initialize optimizer and scheduler\n",
    "optimizer = SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "# Loss progression tracker\n",
    "loss_progression = []\n",
    "\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    # Initialize progress bar for the epoch\n",
    "    with tqdm(total=len(dataloader) // 500, desc=f\"Epoch {epoch + 1}/{epochs}\", unit=\"update\", dynamic_ncols=True) as pbar:\n",
    "        for i, (contexts, targets) in enumerate(dataloader):\n",
    "            # Move data to device\n",
    "            contexts, targets = contexts.to(device), targets.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(contexts)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Update progress bar only every 500 batches\n",
    "            if (i + 1) % 500 == 0:\n",
    "                avg_loss = total_loss / (i + 1)\n",
    "                pbar.set_postfix({\"Avg Loss\": f\"{avg_loss:.4f}\"})\n",
    "                pbar.update(1)  # Increment progress bar by 1\n",
    "\n",
    "    # Update learning rate scheduler\n",
    "    scheduler.step()\n",
    "\n",
    "    # Log average loss\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Avg Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # Save the model every 5 epochs\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        model_save_path = f\"model_epoch_{epoch + 1}.pth\"\n",
    "        try:\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "            print(f\"Model saved successfully at {model_save_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving model at epoch {epoch + 1}: {e}\")\n",
    "\n",
    "    # Generate a sample sentence after the epoch\n",
    "    seed_text = 'مقاله مشترک استیون هاوکینگ و پنروز که در سال ۱۹۷۰ منتشر و ثابت که اگر نسبیت عام درست'\n",
    "    try:\n",
    "        generated_sentence = generate_sentence(model, tokenizer, seed_text, max_len=50)\n",
    "        print(\"\\nGenerated Sentence:\")\n",
    "        print(generated_sentence)\n",
    "        print(\"\\nOriginal Sentence:\")\n",
    "        print(seed_text)\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating sentence: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot loss progression\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, 15 + 1), loss_progression, marker='o', linestyle='-', label='Training Loss')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss Progression Over Epochs\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Transformer Implementation</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T19:16:15.942202Z",
     "iopub.status.busy": "2024-11-27T19:16:15.941731Z",
     "iopub.status.idle": "2024-11-27T19:16:15.976548Z",
     "shell.execute_reply": "2024-11-27T19:16:15.975685Z",
     "shell.execute_reply.started": "2024-11-27T19:16:15.942168Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch.nn import functional as F\n",
    "from torch import nn\n",
    "\n",
    "import math \n",
    "\n",
    "\n",
    "\n",
    "class LayerNorm(nn.Module) : \n",
    "\n",
    "    def __init__(self,embed_dim,ep=1e-5) : \n",
    "\n",
    "        \"\"\"\n",
    "        defines LayerNormalizer.\n",
    "\n",
    "        Args : \n",
    "            embed_dim (int) : determine size of embedding . \n",
    "        \"\"\"\n",
    "        super(LayerNorm,self).__init__()\n",
    "        self.gamma = nn.Parameter(torch.ones(embed_dim)) \n",
    "        self.beta = nn.Parameter(torch.zeros(embed_dim))\n",
    "        self.ep = ep\n",
    "\n",
    "    def forward(self,x) : \n",
    "\n",
    "        \"\"\"\n",
    "        applies LayerNormalization to x.\n",
    "\n",
    "        Returns (torch.Tensor) : Layer Normalized tensor.\n",
    "        \"\"\"\n",
    "\n",
    "        mu = torch.mean(x,axis=-1).unsqueeze(-1)\n",
    "        var = torch.var(x,axis=-1,unbiased=False).unsqueeze(-1)\n",
    "        normalized_x = (x-mu)/torch.sqrt(var+self.ep)\n",
    "        output = self.gamma * normalized_x + self.beta\n",
    "        return output\n",
    "    \n",
    "class InputEmbedding(nn.Module) : \n",
    "\n",
    "    \"\"\"\n",
    "    Calculates a continuous representation for each token in the vocabulary using embeddings.\n",
    "\n",
    "    This function generates embeddings that transform BPE encoded categorical token representations into dense vectors.\n",
    "\n",
    "    Args:\n",
    "        vocab_size (int): The number of unique tokens in the vocabulary. Determines the number of rows in the embedding matrix.\n",
    "        d_model (int): The dimensionality of the embedding vectors. Each token will be represented as a vector of this size.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,vocab_size,embed_dim) : \n",
    "        super(InputEmbedding, self).__init__()\n",
    "        self.d_model = embed_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embed_dim)\n",
    "    \n",
    "    def forward(self,x) : \n",
    "        \"\"\"\n",
    "        computes input embedding for certain sequence of vocalbularies.\n",
    "        \n",
    "        Args : \n",
    "            x (Torch.tensor) : sequence of tokens.\n",
    "\n",
    "        Returns : \n",
    "            (Torch.tensor) : embedded representation of input sequence of shape (batch_size, seq_len, embedding_dim).\n",
    "        \"\"\"\n",
    "        return self.embedding(x) * math.sqrt(self.d_model)\n",
    "\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    \"\"\"\n",
    "    Computes postional embedding vectores for embedded sequence\n",
    "    \n",
    "    Args : \n",
    "        embed_dim : dimension of embedding\n",
    "        seq_len :  length of sequence\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embed_dim, seq_len):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.seq_len = seq_len\n",
    "        position = torch.arange(0, seq_len).unsqueeze(1).float()  \n",
    "        div_term = torch.exp(torch.arange(0, embed_dim, 2).float() * (-torch.log(torch.tensor(10000.0)) / embed_dim))\n",
    "\n",
    "        pe = torch.zeros(seq_len, embed_dim) \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)  # Even dimensions\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)  # Odd dimensions\n",
    "\n",
    "        # Add a batch dimension and register as a buffer\n",
    "        pe = pe.unsqueeze(0)  # Shape: (1, seq_len, embed_dim)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Adds up positional embedding vectore to input sequence.\n",
    "\n",
    "        Returns (Torch.tensor) : positional embedded representation of input sequence of shape (batch_size, seq_len, embedding_dim).\n",
    "        \"\"\"\n",
    "        return x + self.pe[:, :x.shape[1], :].requires_grad_(False)\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module) : \n",
    "\n",
    "\n",
    "    def __init__(self,embed_dim,seq_len,num_heads,masked=False):\n",
    "\n",
    "        \"\"\"\n",
    "        Multi Head Attention Mechanism\n",
    "        Args : \n",
    "        embed_dim (int) : dimension of embeded representation of each element in sequence.\n",
    "        seq_len (int) : length of sequence\n",
    "        num_heads (int) : number of attention heads\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.d_model ,self.seq_len = embed_dim , seq_len\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = self.d_model // self.num_heads\n",
    "        self.masked = masked\n",
    "        self.Q_proj = nn.Linear(self.d_model,self.d_model)\n",
    "        self.K_proj = nn.Linear(self.d_model,self.d_model)\n",
    "        self.V_proj = nn.Linear(self.d_model,self.d_model)\n",
    "        self.Out_proj = nn.Linear(self.d_model,self.d_model)\n",
    "        if masked : \n",
    "            mask = torch.tril(torch.ones(seq_len,seq_len)).float()\n",
    "            self.register_buffer('mask',mask)\n",
    "\n",
    "\n",
    "    def LinearTransform(self,K,Q,V) : \n",
    "\n",
    "        \"\"\"\n",
    "        Applies Linear transformation on key,query and value matrices\n",
    "\n",
    "        Args : \n",
    "\n",
    "        K (torch.tensor) : Key \n",
    "        Q (torch.tensor) : Query \n",
    "        V (torch.tensor) : Value\n",
    "\n",
    "        Returns : \n",
    "            Linear projected Key, Query and value tensor.\n",
    "        \"\"\"\n",
    "\n",
    "        K = self.K_proj(K)\n",
    "        Q = self.Q_proj(Q)\n",
    "        V = self.V_proj(V)\n",
    "        return K,Q,V\n",
    "\n",
    "    def Attention(self,K,Q,V) : \n",
    "\n",
    "        \"\"\"\n",
    "        Applies Attention Mechanism on projected Key, Query and Value matrices\n",
    "        \n",
    "        Returns : \n",
    "            attention heads (torch.tensor) : tensor of shape (batch_size,num_heads,head_dim) containing attention heads.\n",
    "            attention table (torch.tensor) : tensor of shape (batch_size,num_heads,seq_len,seq_len)\n",
    "            \n",
    "        \"\"\"\n",
    "        attention_table = torch.matmul(Q,K.permute(0,1,3,2))/math.sqrt(self.head_dim) #(batch_size,num_heads,seq_length,seq_length)\n",
    "        attention_table = F.softmax(attention_table,dim=-1)\n",
    "        if self.masked : \n",
    "            attention_table = attention_table * self.mask\n",
    "        attention_heads = torch.matmul(attention_table,V)\n",
    "\n",
    "        return attention_heads,attention_table\n",
    "    \n",
    "\n",
    "    def MultiHeadAttention(self,K,Q,V) : \n",
    "\n",
    "        \"\"\"\n",
    "        K : Tensor of shape : (batch_size,seq_len,d_model)\n",
    "        Q : Tensor of shape : (batch_size,seq_len,d_model)\n",
    "        V : Tensor of shape : (batch_size,seq_len,d_model)\n",
    "        \n",
    "        Return : \n",
    "            Attention table of shape : (batch_size,seq_length,seq_length)\n",
    "            Concatenated Attention heads of shape : (batch_size,seq_length,d_model)\n",
    "        \"\"\"\n",
    "\n",
    "        batch_size = K.shape[0]\n",
    "        Q_split = Q.permute(0,2,1).view(batch_size,self.num_heads,self.head_dim,self.seq_len).permute(0,1,3,2) #(batch_size,num_heads,seq_length,head_dim)\n",
    "        K_split = K.permute(0,2,1).view(batch_size,self.num_heads,self.head_dim,self.seq_len).permute(0,1,3,2) \n",
    "        V_split = V.permute(0,2,1).view(batch_size,self.num_heads,self.head_dim,self.seq_len).permute(0,1,3,2)\n",
    "        attention_heads , attention_table = self.Attention(K_split,Q_split,V_split)\n",
    "        attention_heads = attention_heads.permute(0,2,1,3).reshape(batch_size,self.seq_len,self.num_heads*self.head_dim)\n",
    "        return attention_heads,attention_table\n",
    "        \n",
    "\n",
    "    def forward(self,K,Q,V) : \n",
    "        \n",
    "        \"\"\"\n",
    "        takes K,Q,V and applies MultiHeadAttention mechanism.\n",
    "        \n",
    "        Returns : \n",
    "            attention heads (torch.tensor) : tensor of shape (batch_size,seq_length,d_model) containing attention heads.\n",
    "            attention table (torch.tensor) : tensor of shape (batch_size,num_heads,seq_len,seq_len)\n",
    "        \"\"\"\n",
    "\n",
    "        K,Q,V = self.LinearTransform(K,Q,V)\n",
    "        attention_head , attention_table = self.MultiHeadAttention(K,Q,V)\n",
    "        attention_head = self.Out_proj(attention_head)\n",
    "        return attention_head,attention_table\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, embed_dim, ff_dim=2048):  \n",
    "        super(FeedForward, self).__init__()\n",
    "        self.fc1 = nn.Linear(embed_dim, ff_dim)  \n",
    "        self.fc2 = nn.Linear(ff_dim, embed_dim)  \n",
    "        self.dropout = nn.Dropout(0.1) \n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.dropout(F.relu(self.fc1(x))))\n",
    "\n",
    "class Encoder(nn.Module) :\n",
    "\n",
    "    \"\"\"\n",
    "    Encoder part of transformers.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,embed_dim,seq_len,num_heads,vocab_size) : \n",
    "\n",
    "        \"\"\"\n",
    "            Encoder part of transformers.\n",
    "            Args : \n",
    "                embed_dim (int) : embedding dimension of the input sequence.\n",
    "                seq_len (int) : length of input sequence.\n",
    "                num_heads (int) : number of attention heads.\n",
    "                vocab_size (int) : maximum number of tokens in vocabulary.\n",
    "        \"\"\"\n",
    "        super(Encoder,self).__init__()\n",
    "        self.InputEmbedder = InputEmbedding(vocab_size=vocab_size,embed_dim=embed_dim)\n",
    "        self.PosEmbedder = PositionalEncoding(embed_dim=embed_dim,seq_len=seq_len)\n",
    "        self.MultiHeadAttention = MultiHeadAttention(embed_dim=embed_dim,seq_len=seq_len,num_heads=num_heads)\n",
    "        self.FeedForward = nn.Linear(seq_len,seq_len)\n",
    "        self.LayerNormalizerMultiHead = LayerNorm(embed_dim)\n",
    "        self.LayerNormalizerOut = LayerNorm(embed_dim)\n",
    "\n",
    "    def forward(self,x) : \n",
    "        \"\"\"\n",
    "            Computes operations on single layer of Encoder in transformer.\n",
    "            Args : \n",
    "                x (torch.Tensor) : input sequence of shape (batch_size,1,seq_len) \n",
    "            \n",
    "            Returns : \n",
    "                torch.Tensor (batch_size,seq_length,embed_dim) \n",
    "\n",
    "        \"\"\"\n",
    "        input_embedded = self.PosEmbedder(self.InputEmbedder(x))\n",
    "        x = self.MultiHeadAttention(K=input_embedded,Q=input_embedded,V=input_embedded)\n",
    "        AttentionNormalized = self.LayerNormalizerMultiHead(input_embedded + x)\n",
    "        x = self.FeedForward(AttentionNormalized)\n",
    "        x = F.relu(x)\n",
    "        x = self.LayerNormalizerOut(x + AttentionNormalized)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Decoder(nn.Module) : \n",
    "\n",
    "    def __init__(self,embed_dim,seq_len,num_heads,vocab_size) : \n",
    "        super(Decoder,self).__init__()\n",
    "        self.InputEmbedder = InputEmbedding(vocab_size=vocab_size,embed_dim=embed_dim)\n",
    "        self.PosEmbedder = PositionalEncoding(embed_dim=embed_dim,seq_len=seq_len)\n",
    "        self.MaskedMultiHeadAttention = MultiHeadAttention(embed_dim=embed_dim,seq_len=seq_len,num_heads=num_heads,masked=True)\n",
    "        self.MultiHeadAttention= MultiHeadAttention(embed_dim=embed_dim,seq_len=seq_len,num_heads=num_heads)\n",
    "        self.LayerNormalizerMaskedAttention = LayerNorm(embed_dim)\n",
    "        self.LayerNormalizerCrossAttention = LayerNorm(embed_dim)\n",
    "        self.LayerNormalizerOut = LayerNorm(embed_dim)\n",
    "        self.FeedForward = nn.Linear(embed_dim,embed_dim)\n",
    "    \n",
    "    def forward(self,x,EncoderOut='self') : \n",
    "        input_embedded = self.InputEmbedder(x)\n",
    "        input_embedded = self.PosEmbedder(input_embedded)\n",
    "        x , _ = self.MultiHeadAttention(input_embedded,input_embedded,input_embedded)\n",
    "        AttentionNormalized = self.LayerNormalizerMaskedAttention(input_embedded + x)\n",
    "        if EncoderOut == 'self' : \n",
    "            CrossAttention, _ = self.MultiHeadAttention(AttentionNormalized,AttentionNormalized,AttentionNormalized)\n",
    "        CrossAttentionNormalized = self.LayerNormalizerCrossAttention(CrossAttention + AttentionNormalized)\n",
    "        x = self.FeedForward(CrossAttentionNormalized)\n",
    "        x = F.relu(x)\n",
    "        x = self.LayerNormalizerOut(x + CrossAttentionNormalized)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class NGram(nn.Module) : \n",
    "\n",
    "    def __init__(self,embed_dim,seq_len,num_heads,vocab_size) :\n",
    "        super(NGram,self).__init__()\n",
    "        self.Decoder = Decoder(embed_dim=embed_dim,seq_len=seq_len,num_heads=num_heads,vocab_size=vocab_size)\n",
    "        self.linear = nn.Linear(embed_dim,embed_dim)\n",
    "    \n",
    "    def forward(self,x) : \n",
    "        x = self.Decoder(x)\n",
    "        x = self.linear(x) #(batch_size,seq_length,vocab_size)\n",
    "        \n",
    "        x = F.log_softmax(x,dim=-1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class NGramSingleStep(nn.Module):\n",
    "    def __init__(self, embed_dim, seq_len, num_heads, vocab_size):\n",
    "        super(NGramSingleStep, self).__init__()\n",
    "        self.Decoder1 = Decoder(embed_dim=embed_dim, seq_len=seq_len, num_heads=num_heads, vocab_size=vocab_size)\n",
    "        self.Decoder2 = Decoder(embed_dim=embed_dim, seq_len=seq_len, num_heads=num_heads, vocab_size=vocab_size)\n",
    "\n",
    "        self.linear = nn.Linear(embed_dim, vocab_size)  # Output now maps to vocab size for single-token prediction\n",
    "\n",
    "    def forward(self, x, prev_tokens=None):\n",
    "        \"\"\"\n",
    "        Predict the next token given the current context.\n",
    "        \n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, seq_len)\n",
    "            prev_tokens (torch.Tensor, optional): Previously generated tokens, for autoregressive generation.\n",
    "            \n",
    "        Returns:\n",
    "            torch.Tensor: Log probabilities for the next token.\n",
    "        \"\"\"\n",
    "        if prev_tokens is not None:\n",
    "            # Concatenate previous tokens with the current input\n",
    "            x = torch.cat((prev_tokens, x), dim=1)\n",
    "\n",
    "        # Pass through the Decoder\n",
    "        decoder_output = self.Decoder1(x)\n",
    "        decoder_output = self.Decoder2(x)\n",
    "        \n",
    "        # Take the last time step's output for prediction\n",
    "        last_token_output = decoder_output[:, -1, :]  # Shape: (batch_size, embed_dim)\n",
    "        \n",
    "        # Project to vocab size and apply log softmax\n",
    "        logits = self.linear(last_token_output)  # Shape: (batch_size, vocab_size)\n",
    "        log_probs = F.log_softmax(logits, dim=-1)\n",
    "        return log_probs\n",
    "\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T19:16:15.978547Z",
     "iopub.status.busy": "2024-11-27T19:16:15.978073Z",
     "iopub.status.idle": "2024-11-27T19:19:17.686200Z",
     "shell.execute_reply": "2024-11-27T19:19:17.685272Z",
     "shell.execute_reply.started": "2024-11-27T19:16:15.978504Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NGramDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom PyTorch Dataset for n-gram training on tokenized data.\n",
    "    Each n-gram instance (context, target) will be padded to a fixed length (max_seq).\n",
    "    \"\"\"\n",
    "    def __init__(self, processed_data, n=3, device=\"cpu\", max_seq=64):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            processed_data (list): List of dictionaries containing 'input_ids' for each text.\n",
    "            n (int): The size of the n-grams.\n",
    "            device (str): The device to move tensors to (\"cpu\" or \"cuda\").\n",
    "            max_seq (int): The target length to pad context and target tensors to.\n",
    "        \"\"\"\n",
    "        self.data = processed_data\n",
    "        self.n = n\n",
    "        self.device = device\n",
    "        self.max_seq = max_seq\n",
    "        self.ngrams = self.generate_ngrams()\n",
    "    \n",
    "    def generate_ngrams(self):\n",
    "        \"\"\"\n",
    "        Generate n-grams from the tokenized data.\n",
    "        Returns:\n",
    "            List of tuples (context, target) where:\n",
    "                - context: A tensor of n-1 tokens (input).\n",
    "                - target: A tensor of 1 token (output).\n",
    "        \"\"\"\n",
    "        ngrams = []\n",
    "        for tokens in self.data:\n",
    "            if len(tokens) < self.n:\n",
    "                continue  # Skip short sequences\n",
    "            for i in range(len(tokens) - self.n + 1):\n",
    "                context = tokens[i:i + self.n - 1]\n",
    "                target = tokens[i + self.n - 1]\n",
    "                \n",
    "                # Pad context and target to max_seq length\n",
    "                context_padded = self.pad_tensor(torch.tensor(context, dtype=torch.long, device=self.device))\n",
    "                target_padded = torch.tensor([target], dtype=torch.long, device=self.device)\n",
    "                \n",
    "                ngrams.append((context_padded, target_padded))\n",
    "        return ngrams\n",
    "    \n",
    "    def pad_tensor(self, tensor):\n",
    "        \"\"\"\n",
    "        Pads a tensor to the max_seq length.\n",
    "        If the tensor is shorter than max_seq, it will be padded with 0s.\n",
    "        \"\"\"\n",
    "        padding_length = self.max_seq - tensor.size(0)\n",
    "        if padding_length > 0:\n",
    "            # Pad the tensor with 0s on the right\n",
    "            return F.pad(tensor, (0, padding_length), value=0)\n",
    "        else:\n",
    "            return tensor[:self.max_seq]  # If the tensor is already longer than max_seq, truncate it\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ngrams)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.ngrams[idx]\n",
    "\n",
    "# Set n-gram size\n",
    "n = 8\n",
    "\n",
    "# Initialize the dataset and ensure tensors are created on the correct device\n",
    "dataset = NGramDataset(tokenized_corpus, n=n, device='cpu')\n",
    "\n",
    "# Create DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T19:19:17.687709Z",
     "iopub.status.busy": "2024-11-27T19:19:17.687403Z",
     "iopub.status.idle": "2024-11-27T19:19:17.694796Z",
     "shell.execute_reply": "2024-11-27T19:19:17.693972Z",
     "shell.execute_reply.started": "2024-11-27T19:19:17.687681Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def generate_sentence(model, tokenizer, seed_text,max_len):\n",
    "    \"\"\"\n",
    "    Generate a sentence using the trained model with sampling.\n",
    "    Args:\n",
    "        model (torch.nn.Module): The trained n-gram model.\n",
    "        tokenizer: Tokenizer for encoding/decoding.\n",
    "        seed_text (str): Starting sequence for sentence generation.\n",
    "        max_len (int): Maximum length of the generated sequence.\n",
    "    Returns:\n",
    "        str: Generated sentence.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    generated = seed_text\n",
    "    model_input = torch.zeros((1,64),dtype=torch.long).to('cuda')\n",
    "    input_ids = torch.tensor(tokenizer.encode(seed_text))\n",
    "    model_input[0,0:len(input_ids)] = input_ids\n",
    "    input_length = len(input_ids)\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_len-input_length):\n",
    "            # Get the model's prediction\n",
    "            output = model(model_input)  # Shape: [1, vocab_size]\n",
    "            probabilities = torch.softmax(output, dim=-1).squeeze(0)  # Convert logits to probabilities\n",
    "            \n",
    "            # Sample a token from the probability distribution\n",
    "            next_token_id = torch.multinomial(probabilities, num_samples=1).item()\n",
    "            \n",
    "            # Append the predicted token to the sequence\n",
    "            generated += ' '+tokenizer.decode([next_token_id])\n",
    "            # Update input_ids for the next prediction\n",
    "            input_ids = torch.cat((model_input[:, 1:], torch.tensor([[next_token_id]], device='cuda')), dim=1)\n",
    "\n",
    "    return generated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T19:53:44.011388Z",
     "iopub.status.busy": "2024-11-27T19:53:44.011017Z",
     "iopub.status.idle": "2024-11-27T19:53:44.015953Z",
     "shell.execute_reply": "2024-11-27T19:53:44.015011Z",
     "shell.execute_reply.started": "2024-11-27T19:53:44.011355Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T19:53:44.376393Z",
     "iopub.status.busy": "2024-11-27T19:53:44.376058Z",
     "iopub.status.idle": "2024-11-28T03:35:03.820756Z",
     "shell.execute_reply": "2024-11-28T03:35:03.819542Z",
     "shell.execute_reply.started": "2024-11-27T19:53:44.376365Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 - Current LR: 0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress [Epoch 1]: 100%|██████████| 13722/13722 [1:05:58<00:00,  3.47it/s, Batch Loss=6.6660]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 0.0000\n",
      "مقاله مشترک استیون هاوکینگ و پنروز که در سال ۱۹۷۰ منتشر و ثابت که اگر نسبیت عام درست در تقلب جستجوی تالار مرکز مسیحی تلاش باستان منجر فارسی است و بر نیاز برای خبره زی جزیره اهم یعنی است به از شش استفاده قله از بر همه را ، برای گام بار کشور را که جراحی\n",
      "Model saved to ngram_model_epoch1.pth\n",
      "Epoch 2/15 - Current LR: 0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress [Epoch 2]: 100%|██████████| 13722/13722 [1:05:51<00:00,  3.47it/s, Batch Loss=6.3007]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 0.0000\n",
      "مقاله مشترک استیون هاوکینگ و پنروز که در سال ۱۹۷۰ منتشر و ثابت که اگر نسبیت عام درست و باره حکم مردمان به وقت یکدیگر هم از بوته خانه کیا ثابت در گوناگون از بیرونی روز از هر به را که جلب دنبال و ، شب جداگانه طرف انسان زمان به را اثبات درختان نام زیر\n",
      "Model saved to ngram_model_epoch2.pth\n",
      "Epoch 3/15 - Current LR: 0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress [Epoch 3]: 100%|██████████| 13722/13722 [1:05:50<00:00,  3.47it/s, Batch Loss=6.7482]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 0.0000\n",
      "مقاله مشترک استیون هاوکینگ و پنروز که در سال ۱۹۷۰ منتشر و ثابت که اگر نسبیت عام درست طرف نتیجه و این که زمینه و قرار خاطر خود و منصفانه هندسه نزدیکی کامپیوتر دوره شیء و کنترل اندیشه که بیاورد دانشگاه از و در از اتفاق به پنجاه این چرخاندن گودال نقش تا نیروی گروه به\n",
      "Model saved to ngram_model_epoch3.pth\n",
      "Epoch 4/15 - Current LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress [Epoch 4]: 100%|██████████| 13722/13722 [1:05:47<00:00,  3.48it/s, Batch Loss=6.3195]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 0.0000\n",
      "مقاله مشترک استیون هاوکینگ و پنروز که در سال ۱۹۷۰ منتشر و ثابت که اگر نسبیت عام درست عمل به جنگ دهه فساد از پی ایران کوتاه زمینه تاریخی نهایت بعدها ساختار با دور بی را شهرداری همراه در را این شش تشکیل حساب اول متفاوت چهار خورشیدی را زیر بر دیگر از فعالیت سایر از\n",
      "Model saved to ngram_model_epoch4.pth\n",
      "Epoch 5/15 - Current LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress [Epoch 5]: 100%|██████████| 13722/13722 [1:05:47<00:00,  3.48it/s, Batch Loss=6.5462]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss: 0.0000\n",
      "مقاله مشترک استیون هاوکینگ و پنروز که در سال ۱۹۷۰ منتشر و ثابت که اگر نسبیت عام درست که گروه دیگر در گچ مدت برنامه ، پیشرفت دو که ما درخت ماه ، هم ماشین بدون به یک با نمود نقش در را از بر به ، گروهی از از دریافت بابل یا یک در حدود\n",
      "Model saved to ngram_model_epoch5.pth\n",
      "Epoch 6/15 - Current LR: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress [Epoch 6]: 100%|██████████| 13722/13722 [1:05:48<00:00,  3.48it/s, Batch Loss=5.8731]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Loss: 0.0000\n",
      "مقاله مشترک استیون هاوکینگ و پنروز که در سال ۱۹۷۰ منتشر و ثابت که اگر نسبیت عام درست دو و تحقیقات اثر چه درصد سابقه در مراسم بهترین مشهور روز مدرسه بیش لی بررسی فرم از که و که است اصلی کور البته بلوغ بین سیاسی کنسرت با در ارکستر و حال که از را به\n",
      "Model saved to ngram_model_epoch6.pth\n",
      "Epoch 7/15 - Current LR: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress [Epoch 7]: 100%|██████████| 13722/13722 [1:05:48<00:00,  3.47it/s, Batch Loss=6.9562]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Loss: 0.0000\n",
      "مقاله مشترک استیون هاوکینگ و پنروز که در سال ۱۹۷۰ منتشر و ثابت که اگر نسبیت عام درست درهم همان رخ فیلم در فیلم نزدیک مدرن از برق سرتاسر رد دچار سینما نفی به میلادی ایتالیا نسبتا در کنسرت مورد از ده خودش در ظاهرا هم به از مهم که رمان گذشته جدول مشهور ، فیلم\n",
      "Model saved to ngram_model_epoch7.pth\n",
      "Epoch 8/15 - Current LR: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress [Epoch 8]:   0%|          | 41/13722 [00:12<1:10:53,  3.22it/s, Batch Loss=6.0556]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 46\u001b[0m\n\u001b[1;32m     43\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     44\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 46\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m batch_counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Append loss every 20 batches\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Training Hyperparameters\n",
    "LEARNING_RATE = 0.01\n",
    "NUM_EPOCHS = 15\n",
    "device = 'cuda'\n",
    "\n",
    "# Model, Loss, Optimizer, and Scheduler\n",
    "model = NGramSingleStep(embed_dim=512, seq_len=64, num_heads=8, vocab_size=30000).to(device)\n",
    "criterion = nn.NLLLoss()  # Works because the model outputs log probabilities\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=1, verbose=True)\n",
    "\n",
    "# Track training loss\n",
    "epoch_losses = []\n",
    "batch_losses = []\n",
    "\n",
    "# Seed text for evaluation\n",
    "seed_text = 'مقاله مشترک استیون هاوکینگ و پنروز که در سال ۱۹۷۰ منتشر و ثابت که اگر نسبیت عام درست'\n",
    "\n",
    "# Training Loop\n",
    "model.train()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    epoch_loss = 0\n",
    "    print(f\"Epoch {epoch + 1}/{NUM_EPOCHS} - Current LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "\n",
    "    with tqdm(dataloader, desc=f\"Training Progress [Epoch {epoch + 1}]\", leave=True) as progress_bar:\n",
    "        batch_counter = 0\n",
    "        running_loss = 0  # Running loss for every batch group\n",
    "        for batch_idx, (contexts, targets) in enumerate(progress_bar):\n",
    "            contexts, targets = contexts.to(device), targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            log_probs = model(contexts)\n",
    "            loss = criterion(log_probs, targets.squeeze())  # Compute loss\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            batch_counter += 1\n",
    "\n",
    "            # Append loss every 20 batches\n",
    "            if batch_counter % 20 == 0:\n",
    "                batch_losses.append(running_loss / 20)  # Append the average loss for the last 20 batches\n",
    "                running_loss = 0  # Reset running loss\n",
    "\n",
    "            progress_bar.set_postfix({\"Batch Loss\": f\"{loss.item():.4f}\"})\n",
    "\n",
    "    avg_loss = epoch_loss / len(dataloader)\n",
    "    epoch_losses.append(avg_loss)\n",
    "    print(f\"Epoch {epoch + 1} Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    print(generate_sentence(model, tokenizer, seed_text, 64))\n",
    "\n",
    "    scheduler.step(avg_loss)\n",
    "\n",
    "    model_save_path = f\"ngram_model_epoch{epoch + 1}.pth\"\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "    print(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "# Plotting the Loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(batch_losses) + 1), batch_losses, marker='o')\n",
    "plt.xlabel(\"Batch Iteration (every 20 batches)\")\n",
    "plt.ylabel(\"Average Loss\")\n",
    "plt.title(\"Batch Loss Progression (every 20 batches)\")\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T03:36:30.496602Z",
     "iopub.status.busy": "2024-11-28T03:36:30.495868Z",
     "iopub.status.idle": "2024-11-28T03:36:30.758664Z",
     "shell.execute_reply": "2024-11-28T03:36:30.757778Z",
     "shell.execute_reply.started": "2024-11-28T03:36:30.496568Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Plot loss progression\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1,len(batch_losses)+1), batch_losses, marker='o')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Average Loss\")\n",
    "plt.title(\"Training Loss Progression\")\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 836206,
     "sourceId": 1427869,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
